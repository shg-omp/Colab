{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shg-omp/Colab/blob/main/%5BOMP%5D_TemplateGenerator_TargetSites.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38LEPkvPxPsB"
      },
      "source": [
        "<img style=\"float:center\" src=\"https://raw.githubusercontent.com/AndreaDeFilippo/icons/main/company/showheroes-group-logo.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLDNB9Dy2a5L"
      },
      "source": [
        "# **Add Target Sites - template_video Generator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZF-rCeexpBO"
      },
      "source": [
        "This Tool consists in the automatic generation of the template_video .csv to be used for the AdSources Video section.\n",
        "\n",
        "The structure of the script is based on:\n",
        "\n",
        "\n",
        "*   [[OM] - DB](https://docs.google.com/spreadsheets/d/1l8Gm8NqZIDhitZ-N3y8xaYl-_KCQfIIUi4L5962xXyM/edit#gid=0)\n",
        "*   [[TOOL] - Add Target Sites](https://docs.google.com/spreadsheets/d/14eW8HcmukU5KphTngRhzze0htUoZ56-XGUX_BdbGc-s/edit#gid=0)\n",
        "\n",
        "In the Gsheet **[TOOL] - Add Target Sites** you have to insert the domains for which you want to generate the template_video for the insertion in the AdSources Video where the domain is approved.\n",
        "\n",
        "A .xlsx file will be generated to have a summary of where the domains will be inserted in the respective AdSources while the .csv file is the one to use for the *Add Target Sites* on the platform.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JkWPRi_8xx7e"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import pandas as pd\n",
        "from functools import reduce\n",
        "import time\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "pd.set_option('mode.chained_assignment', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "bcf-1Haaxz_-",
        "outputId": "b4583ce0-2c52-4751-db22-f5d1dd0f82e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-50886122aec1>:14: DtypeWarning: Columns (9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  db = pd.read_csv(db)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7c9f459a1db0>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_fcc81_row0_col0, #T_fcc81_row0_col1, #T_fcc81_row0_col2, #T_fcc81_row0_col3, #T_fcc81_row0_col4, #T_fcc81_row0_col9, #T_fcc81_row0_col11, #T_fcc81_row0_col12, #T_fcc81_row0_col13, #T_fcc81_row0_col14, #T_fcc81_row0_col15, #T_fcc81_row0_col16 {\n",
              "  background-color: None;\n",
              "}\n",
              "#T_fcc81_row0_col5, #T_fcc81_row0_col6, #T_fcc81_row0_col7, #T_fcc81_row0_col8, #T_fcc81_row0_col10 {\n",
              "  background-color: seagreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_fcc81\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_fcc81_level0_col0\" class=\"col_heading level0 col0\" >Domain</th>\n",
              "      <th id=\"T_fcc81_level0_col1\" class=\"col_heading level0 col1\" >Status</th>\n",
              "      <th id=\"T_fcc81_level0_col2\" class=\"col_heading level0 col2\" >PP OutStream</th>\n",
              "      <th id=\"T_fcc81_level0_col3\" class=\"col_heading level0 col3\" >PP InStream</th>\n",
              "      <th id=\"T_fcc81_level0_col4\" class=\"col_heading level0 col4\" >Rubicon</th>\n",
              "      <th id=\"T_fcc81_level0_col5\" class=\"col_heading level0 col5\" >Freewheel</th>\n",
              "      <th id=\"T_fcc81_level0_col6\" class=\"col_heading level0 col6\" >Improve</th>\n",
              "      <th id=\"T_fcc81_level0_col7\" class=\"col_heading level0 col7\" >Adform</th>\n",
              "      <th id=\"T_fcc81_level0_col8\" class=\"col_heading level0 col8\" >Smart</th>\n",
              "      <th id=\"T_fcc81_level0_col9\" class=\"col_heading level0 col9\" >Union</th>\n",
              "      <th id=\"T_fcc81_level0_col10\" class=\"col_heading level0 col10\" >Pubmatic</th>\n",
              "      <th id=\"T_fcc81_level0_col11\" class=\"col_heading level0 col11\" >OpenX</th>\n",
              "      <th id=\"T_fcc81_level0_col12\" class=\"col_heading level0 col12\" >Xandr</th>\n",
              "      <th id=\"T_fcc81_level0_col13\" class=\"col_heading level0 col13\" >RichAudience</th>\n",
              "      <th id=\"T_fcc81_level0_col14\" class=\"col_heading level0 col14\" >Index</th>\n",
              "      <th id=\"T_fcc81_level0_col15\" class=\"col_heading level0 col15\" >OneTag</th>\n",
              "      <th id=\"T_fcc81_level0_col16\" class=\"col_heading level0 col16\" >Sovrn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_fcc81_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_fcc81_row0_col0\" class=\"data row0 col0\" >1000cuorirossoblu.it</td>\n",
              "      <td id=\"T_fcc81_row0_col1\" class=\"data row0 col1\" >Catchall</td>\n",
              "      <td id=\"T_fcc81_row0_col2\" class=\"data row0 col2\" >1</td>\n",
              "      <td id=\"T_fcc81_row0_col3\" class=\"data row0 col3\" >1</td>\n",
              "      <td id=\"T_fcc81_row0_col4\" class=\"data row0 col4\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col5\" class=\"data row0 col5\" >wl</td>\n",
              "      <td id=\"T_fcc81_row0_col6\" class=\"data row0 col6\" >wl</td>\n",
              "      <td id=\"T_fcc81_row0_col7\" class=\"data row0 col7\" >wl</td>\n",
              "      <td id=\"T_fcc81_row0_col8\" class=\"data row0 col8\" >wl</td>\n",
              "      <td id=\"T_fcc81_row0_col9\" class=\"data row0 col9\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col10\" class=\"data row0 col10\" >wl</td>\n",
              "      <td id=\"T_fcc81_row0_col11\" class=\"data row0 col11\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col12\" class=\"data row0 col12\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col13\" class=\"data row0 col13\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col14\" class=\"data row0 col14\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col15\" class=\"data row0 col15\" >-</td>\n",
              "      <td id=\"T_fcc81_row0_col16\" class=\"data row0 col16\" >-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#@title\n",
        "# URL\n",
        "domain = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRuqZpFwkpJTO3O4O5YyACTRHI1GHYThiQwon9VNkoOXatOEc6aRm4zk5fWrBMqIw_cNjV_i1mq_8_G/pub?gid=542268396&single=true&output=csv'\n",
        "adsources = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRuqZpFwkpJTO3O4O5YyACTRHI1GHYThiQwon9VNkoOXatOEc6aRm4zk5fWrBMqIw_cNjV_i1mq_8_G/pub?gid=1608803443&single=true&output=csv'\n",
        "db = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQ7rqThGh1aVGl_L7HyBixQD8L8i_BsxgNNh46lT_RVzGv2OCDncX3GTYCs4MAE7M8f7KZWW7uKUfJz/pub?gid=0&single=true&output=csv'\n",
        "\n",
        "# Reading the domain\n",
        "df_domain = pd.read_csv(domain)\n",
        "\n",
        "# Create a list of Domain to insert in OMP Sources\n",
        "list_domain = df_domain['Domain'].tolist()\n",
        "\n",
        "# Reading DB about the Audit Status\n",
        "db = pd.read_csv(db)\n",
        "\n",
        "list_ssp = ['Rubicon',\n",
        "           'Freewheel',\n",
        "           'Improve',\n",
        "           'Adform',\n",
        "           'Smart',\n",
        "           'Union',\n",
        "           'Pubmatic',\n",
        "           'OpenX',\n",
        "           'Xandr',\n",
        "           'RichAudience',\n",
        "           'Index',\n",
        "           'OneTag',\n",
        "           'Sovrn']\n",
        "\n",
        "columns = ['Domain', 'Status', 'PP OutStream','PP InStream'] + list_ssp\n",
        "\n",
        "db = db[columns]\n",
        "db = db[db.Domain.isin(list_domain)] # Filter Domains to put in the AdSources\n",
        "\n",
        "db = db.replace(to_replace = ['to_check','bl','to_add','removed'],\n",
        "                value ='-')\n",
        "\n",
        "# Overview about Domain Status\n",
        "def _bg_color(val):\n",
        "    color = 'seagreen' if val == 'wl' else None\n",
        "    return 'background-color: %s' % color\n",
        "\n",
        "db_overview = pd.merge(df_domain, db, how='left', on=['Domain'])\n",
        "db_overview.style.applymap(_bg_color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uim_ODGcln9V"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Creation of the DataFrame about the Pricing Point per Format\n",
        "dict_format = {'Instream' : {'column_db' : 'PP InStream'},\n",
        "               'Outstream' : {'column_db' : 'PP OutStream'}}\n",
        "\n",
        "list_format = ['Instream', 'Outstream']\n",
        "\n",
        "db_format = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XB5YcB1KluuH"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "for vid_format in list_format:\n",
        "    df_format = db[['Domain', dict_format[vid_format]['column_db']]]\n",
        "    df_format['PP'] = df_format[dict_format[vid_format]['column_db']]\n",
        "    df_format['Format'] = vid_format\n",
        "    df_format = df_format[['Domain','Format','PP']]\n",
        "    #db_format = db_format.append(df_format, ignore_index=True)\n",
        "    db_format = pd.concat([db_format, df_format], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YiPkjVUXl7qq"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Creation of the DataFrame about the Audit Status per Domain & SSP\n",
        "db_audit = pd.DataFrame()\n",
        "\n",
        "for ssp in list_ssp:\n",
        "    df_audit = db[['Domain', ssp]]\n",
        "    df_audit['Audit'] = df_audit[ssp]\n",
        "    df_audit['SSP'] = ssp\n",
        "    df_audit = df_audit[['Domain','SSP','Audit']]\n",
        "    #db_audit = db_audit.append(df_audit, ignore_index=True)\n",
        "    db_audit = pd.concat([db_audit,df_audit], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wP-rYavYmNaK"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Creation of the DataFrame about the Status per Domain\n",
        "db_status = db[['Domain', 'Status']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wQ2qcpyLmqlV"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Merging the Domain with the DB\n",
        "dfs = [db_status, db_format, db_audit]\n",
        "df = reduce(lambda left,right: pd.merge(left,right,on='Domain'), dfs)\n",
        "\n",
        "\n",
        "# Isolate the domain with CA Status and positive audit\n",
        "df = df[df['Audit'].str.contains('wl')]\n",
        "df = df[['Domain','Status','Format','PP','SSP']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "dmAyp-HuCZuK"
      },
      "outputs": [],
      "source": [
        "df[\"PP\"] = df[\"PP\"].apply(str)\n",
        "timestamp = time.strftime('%Y%m%d%H%M%S')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8jWn8lXryF2_"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Reading the Sources DB\n",
        "db_sources = pd.read_csv(adsources)\n",
        "db_sources = db_sources[['Type', 'Id', 'Ad Source', 'Status', 'SSP', 'PP', 'Format']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# START Managing exeption for Pubmatic without PP\n",
        "## Creating specific db_sources\n",
        "if db[\"Pubmatic\"].str.contains(\"wl\").any():\n",
        "  db_sources_ppn_Pubmatic = db_sources.query(\" SSP == 'Pubmatic' and Type == 'Video' and PP == '-'  \")\n",
        "\n",
        "  # Video Merging the data and Creation of the .xlsx Recap\n",
        "  df_final_video = pd.merge(df, db_sources, how='left', on=['Status', 'SSP', 'PP', 'Format'])\n",
        "\n",
        "\n",
        "  Pubmatic = [\"Pubmatic\"]\n",
        "  Pubmatic_ppn = df_final_video[df_final_video[\"SSP\"].isin(Pubmatic)]\n",
        "  Pubmatic_ppn = Pubmatic_ppn.Domain.unique()\n",
        "  # Costruisci un DataFrame unico concatenando ciascun elemento dell'array 'pubmatic'\n",
        "  dfs_Pubmatic_ppn = []\n",
        "\n",
        "  for domain in Pubmatic_ppn:\n",
        "      df_Pubmatic_ppn = db_sources_ppn_Pubmatic.copy()  # Crea una copia del DataFrame originale\n",
        "      df_Pubmatic_ppn.insert(0, 'Domain', domain)  # Aggiungi la colonna 'Domain' con l'elemento corrente\n",
        "      dfs_Pubmatic_ppn.append(df_Pubmatic_ppn)  # Aggiungi il DataFrame alla lista\n",
        "\n",
        "  merged_df_Pubmatic_ppn = pd.concat(dfs_Pubmatic_ppn, ignore_index=True)\n",
        "\n",
        "  merged_df_Pubmatic_ppn[\"Status\"] = \"Catchall\"\n",
        "  merged_df_Pubmatic_ppn = merged_df_Pubmatic_ppn[[\"Domain\", \"Status\", \"Format\",\"PP\", \"Type\", \"Id\", \"Ad Source\"]]\n",
        "\n",
        "\n",
        "  df_final_video = pd.concat([df_final_video, merged_df_Pubmatic_ppn])\n",
        "  # END Managing exeption for Pubmatic without PP"
      ],
      "metadata": {
        "id": "NumyiCJda9va"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Ht1QHarWP4XE"
      },
      "outputs": [],
      "source": [
        "# START Managing exeption for OneTag without PP\n",
        "## Creating specific db_sources\n",
        "if db[\"OneTag\"].str.contains(\"wl\").any():\n",
        "  db_sources_ppn_OneTag = db_sources.query(\" SSP == 'OneTag' and Type == 'Video' and PP == '-'  \")\n",
        "\n",
        "\n",
        "  OneTag = [\"OneTag\"]\n",
        "  OneTag_ppn = df_final_video[df_final_video[\"SSP\"].isin(OneTag)]\n",
        "  OneTag_ppn = OneTag_ppn.Domain.unique()\n",
        "  # Costruisci un DataFrame unico concatenando ciascun elemento dell'array 'OneTag'\n",
        "  dfs_OneTag_ppn = []\n",
        "\n",
        "  for domain in OneTag_ppn:\n",
        "      df_OneTag_ppn = db_sources_ppn_OneTag.copy()  # Crea una copia del DataFrame originale\n",
        "      df_OneTag_ppn.insert(0, 'Domain', domain)  # Aggiungi la colonna 'Domain' con l'elemento corrente\n",
        "      dfs_OneTag_ppn.append(df_OneTag_ppn)  # Aggiungi il DataFrame alla lista\n",
        "\n",
        "  merged_df_OneTag_ppn = pd.concat(dfs_OneTag_ppn, ignore_index=True)\n",
        "\n",
        "  merged_df_OneTag_ppn[\"Status\"] = \"Catchall\"\n",
        "  merged_df_OneTag_ppn = merged_df_OneTag_ppn[[\"Domain\", \"Status\", \"Format\",\"PP\", \"Type\", \"Id\", \"Ad Source\"]]\n",
        "\n",
        "\n",
        "  df_final_video = pd.concat([df_final_video, merged_df_OneTag_ppn])\n",
        "  # END Managing exeption for OneTag without PP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ca1LAHdSNh4z"
      },
      "outputs": [],
      "source": [
        "df_final_video.dropna(subset = [\"Id\"], inplace=True)\n",
        "df_final_video = df_final_video[['Domain','Status','Format','PP','Id','Ad Source']]\n",
        "\n",
        "# Display Merging the data and Creation of the .xlsx Recap\n",
        "db_sources = db_sources[db_sources['Type'].isin(['Display'])]\n",
        "db_sources = db_sources[db_sources['Status'].isin(['Catchall'])]\n",
        "df_final_display = pd.merge(df, db_sources, how='left', on=['SSP'])\n",
        "df_final_display.dropna(subset = [\"Id\"], inplace=True)\n",
        "df_final_display = df_final_display[['Domain','Id','Ad Source']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "S8VuWkP7wNoZ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# Adding company id to Apester domains\n",
        "#df_final_video[\"company id\"] = np.where(df_final_video[\"Status\"] == \"Apester\", \"5133\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "q3UCbSwglnVi"
      },
      "outputs": [],
      "source": [
        "### REMOVING FREEWHEEL LINES DUE TO FILL RATE(STR) TREESHOLD\n",
        "df_final_video = df_final_video[df_final_video[\"Ad Source\"].str.contains(\"freewheel\", case=False)==False]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Ook8K5ZIzzPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c30d6f9e-fb5f-4003-9ab0-bda04a7bbb32"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54861d5a-afc6-4564-a421-5c9e219832cb\", \"output_video20240418142658_check.xlsx\", 5912)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3e94de81-27f0-432d-a3b2-9f53686f7c33\", \"output_20240418142658_template_video.csv\", 792)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_04d8280d-cf5b-4494-8669-dbcfbfdd5bab\", \"output_display20240418142658_check.xlsx\", 6231)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c9565967-2a6b-4223-9bcd-7dd7ebdd8238\", \"output_20240418142658_template_display.csv\", 1864)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title\n",
        "'''VIDEO'''\n",
        "\n",
        "# Export Video .xlsx\n",
        "df_final_video.to_excel('output_video'+ timestamp + '_check.xlsx', index=False)\n",
        "files.download('output_video'+ timestamp + '_check.xlsx')\n",
        "\n",
        "# Creation of the .csv template_video\n",
        "template_video = df_final_video[['Id','Domain']]\n",
        "template_video['company id'] = None\n",
        "template_video.rename(columns={'Id': 'source id', 'Domain': 'domain'}, inplace=True)\n",
        "template_video[\"source id\"] = template_video[\"source id\"].astype(int)\n",
        "template_video.to_csv('output_' + timestamp + '_template_video.csv', index=None, sep=',')\n",
        "files.download('output_' + timestamp + '_template_video.csv')\n",
        "\n",
        "'''Display'''\n",
        "\n",
        "# Export Display .xlsx\n",
        "df_final_display.to_excel('output_display'+ timestamp + '_check.xlsx', index=False)\n",
        "files.download('output_display'+ timestamp + '_check.xlsx')\n",
        "\n",
        "# Creation of the .csv template_display\n",
        "template_display = df_final_display[['Id','Domain']]\n",
        "template_display['company id'] = None\n",
        "template_display.rename(columns={'Id': 'source id', 'Domain': 'domain'}, inplace=True)\n",
        "template_display[\"source id\"] = template_display[\"source id\"].astype(int)\n",
        "template_display.to_csv('output_' + timestamp + '_template_display.csv', index=None, sep=',')\n",
        "files.download('output_' + timestamp + '_template_display.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}